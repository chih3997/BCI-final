{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jeYdwqGYjg6Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    print('Loading data...')\n",
        "    data = pd.read_csv(path, sep = \",\", header = None)\n",
        "    n_samples = len(data)\n",
        "    print('Number of samples:', n_samples)\n",
        "    x = data.values[:, :-1].tolist()\n",
        "    y = data.values[:,-1].tolist()\n",
        "    return data, x, y"
      ],
      "metadata": {
        "id": "Pe4hc7OdjirX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(x, y, testset_portion):\n",
        "    print('Split dataset.')\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, \\\n",
        "                                test_size = testset_portion, \\\n",
        "                                random_state = None)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "6T7ymn6cjkXe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_scaling(x_train, x_test):\n",
        "    print('Feature scaling.')\n",
        "    sc = StandardScaler()\n",
        "    sc.fit(x_train)\n",
        "    x_train_nor = sc.transform(x_train)\n",
        "    x_test_nor = sc.transform(x_test)\n",
        "    return x_train_nor, x_test_nor"
      ],
      "metadata": {
        "id": "_cl3YRXnjl8t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_KNN(x_train, y_train, n):\n",
        "    print('Start training.')\n",
        "    clf = KNeighborsClassifier(n_neighbors = n)\n",
        "    clf.fit(x_train, y_train)\n",
        "    return clf"
      ],
      "metadata": {
        "id": "YF9solkRjoYJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(clf, x_test):\n",
        "    print('Start testing...')\n",
        "    y_pred = clf.predict(x_test)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "ure8H2dJjqw-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "#     path = 'feature_all.csv'\n",
        "\n",
        "    path = 'on_off_open.csv'\n",
        "    testset_portion = 0.2\n",
        "\n",
        "    data, x, y = load_data(path)\n",
        "\n",
        "    labels = np.unique(np.array(y))\n",
        "\n",
        "    lb = preprocessing.LabelEncoder()\n",
        "    lb.fit(labels)\n",
        "    y=lb.transform(y)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = split_dataset(x, y, testset_portion)\n",
        "    x_train_nor, x_test_nor = feature_scaling(x_train, x_test)\n",
        "\n",
        "    n = 2\n",
        "\n",
        "    print(\"Training and Testing for KNN:\")\n",
        "    clf_KNN = train_KNN(x_train_nor, y_train, n)\n",
        "    y_pred_KNN = test(clf_KNN, x_test_nor)\n",
        "\n",
        "    acc_KNN = accuracy_score(y_test, y_pred_KNN)\n",
        "    print('\\nAccuracy KNN\\n', round(acc_KNN, 3))\n",
        "\n",
        "    # confusion_mat_KNN = confusion_matrix(y_test, y_pred_KNN)\n",
        "    # print('\\nConfusion Matrix KNN', confusion_mat_KNN)\n",
        "    print('\\nConfusion Matrix KNN\\n', confusion_matrix(y_test, y_pred_KNN))\n",
        "    print('\\nClassification Report KNN\\n', classification_report(y_test, y_pred_KNN))"
      ],
      "metadata": {
        "id": "sxe1LnGxjsgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dea1778-46e0-4cad-da5c-97ffb4afd769"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Number of samples: 336\n",
            "Split dataset.\n",
            "Feature scaling.\n",
            "Training and Testing for KNN:\n",
            "Start training.\n",
            "Start testing...\n",
            "\n",
            "Accuracy KNN\n",
            " 0.721\n",
            "\n",
            "Confusion Matrix KNN\n",
            " [[27  5]\n",
            " [14 22]]\n",
            "\n",
            "Classification Report KNN\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.84      0.74        32\n",
            "           1       0.81      0.61      0.70        36\n",
            "\n",
            "    accuracy                           0.72        68\n",
            "   macro avg       0.74      0.73      0.72        68\n",
            "weighted avg       0.74      0.72      0.72        68\n",
            "\n"
          ]
        }
      ]
    }
  ]
}